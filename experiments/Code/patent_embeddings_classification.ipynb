{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "sys.path.insert(0, 'C:/thesis/transfer-learning-with-feature-selection/')\n",
    "sys.path.insert(0, 'C:/thesis/transfer-learning-with-feature-selection/lib/')\n",
    "sys.path.insert(0, 'C:/thesis/transfer-learning-with-feature-selection/utils/')\n",
    "import lib as lib\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "from random import sample\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lib.similarity import CentroidSimilarity\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from lib.feature_selection import FeatureSelectionDiversityPursuitAnova,FeatureSelectionOneVsAllAnova,FeatureSelectionDiversityPursuitKruskal, FeatureSelectionOneVsAllKS\n",
    "from lib.classifier_with_feature_selection import ClassifierFeatureSelection\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from utils.experiment_utils import multiple_classifiers_fit_predict\n",
    "from utils.experiment_utils import get_feature_extractor, extract_features, preprocessing_model, identity_model, classifiers_hyper_tune\n",
    "from utils.experiment_utils import scan_experiment\n",
    "from utils.experiment_utils import get_images_from_supervised_set\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.visualization import bar_plot_scores\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import time\n",
    "import tiktoken\n",
    "import pickle\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.spatial.distance import cdist\n",
    "from utils.experiment_utils import compute_inter_class_distances\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "models_dir = \"c:/transformer_models/\"\n",
    "if os.path.isdir(models_dir) is not True:\n",
    "    os.mkdir(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dir = \"c:/datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def parse_code_to_levels(code):\n",
    "    split = code.split()\n",
    "    # first part has a letter,double digit number,letter - e.g. 'H04N'. these are the first 3 levels\n",
    "    part_1 = split[0]\n",
    "    l = [part_1[0], part_1[1:3], part_1[3]]\n",
    "    # get part 2 which has a structure [d]/[d]\n",
    "    part_2 = split[1]\n",
    "    # split the second part on the '/'\n",
    "    split_2 = part_2.split('/')\n",
    "    l_4 = split_2[0]\n",
    "    l.append(l_4)\n",
    "    l_5 = split_2[1][:2]\n",
    "    l.append(l_5)\n",
    "    return tuple(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "def get_code_data(tree: dict, code: list, tree_depth: int = 5):\n",
    "    \"\"\"\n",
    "    extracts all patents ids nestled in the tree under the given code\n",
    "    Args:\n",
    "        tree: a data structure of nestled dictionaries where tree nodes are patents classification in\n",
    "        different levels and the leaves are lists of patents\n",
    "        code: a list of strings - each entry is another level in a patent cpcs code\n",
    "        tree_depth : int. maximal tree depth\n",
    "    Returns:\n",
    "        patents - a list of patents all have the same cpcs code\n",
    "    \"\"\"\n",
    "    patents = []\n",
    "    next_level = tree[code[0]]\n",
    "\n",
    "    for i in range(1,len(code)):\n",
    "        # descend down the tree\n",
    "        next_level = next_level[code[i]]\n",
    "    # get all patents in that subtree\n",
    "    return get_tree_leaves(next_level, patents)\n",
    "\n",
    "\n",
    "def get_tree_leaves(tree: Union[dict,list], leaves: list) -> list:\n",
    "    \"\"\"\n",
    "    a recursive function for extracting tree leaves\n",
    "    Args:\n",
    "        tree: may be a dict in case it's a tree with further nodes, or a list if it's the tree leaf\n",
    "        leaves: a list with currently found leaves\n",
    "\n",
    "    Returns:\n",
    "        a new list of leaves with the new ones found in the input tree\n",
    "    \"\"\"\n",
    "    if type(tree) is dict:\n",
    "        for key in tree.keys():\n",
    "            leaves = get_tree_leaves(tree[key], leaves)\n",
    "    else:\n",
    "        leaves.extend(tree)\n",
    "    return leaves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_unique_patents_per_code(codes_to_extract: list, codes_to_patents_mapping: dict):\n",
    "    code_unique_patents = {}\n",
    "    for code in codes_to_extract:\n",
    "        # get all patents for the current code\n",
    "        code_patents = set(get_code_data(codes_to_patents_mapping, code))\n",
    "\n",
    "        # get unified list of patents from all other codes\n",
    "        other_codes = codes_to_extract.copy()\n",
    "        other_codes.remove(code)\n",
    "        other_patents = []\n",
    "        for oc in other_codes:\n",
    "            other_patents.extend(get_code_data(codes_to_patents_mapping, oc))\n",
    "        other_patents = set(other_patents)\n",
    "        code_unique_patents[code] = list(code_patents.difference(other_patents))\n",
    "\n",
    "    return code_unique_patents\n",
    "\n",
    "\n",
    "def get_embeddings(patents_list: list, \n",
    "                   patents_dict: dict, \n",
    "                   embedding_dict: dict, \n",
    "                   embedding_model: str = 'gpt2', \n",
    "                   cohere_client = None, \n",
    "                   cohere_model: str = None,\n",
    "                   batch_size: int = 96) -> np.ndarray:\n",
    "    embeddings = []\n",
    "    batch_patents = []\n",
    "    if embedding_model == 'gpt2':\n",
    "        for p in patents_list:\n",
    "            if p not in embedding_dict.keys():\n",
    "                text = get_abstract(patent_id=p,patents_dict=patents_dict)\n",
    "                input = gpt2_tokenizer(text, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "                with torch.no_grad():\n",
    "                    output = gpt2_model(**input)\n",
    "                    embedding_dict[p] = {'emb' : output.last_hidden_state[:,:,:].numpy().mean(axis=1).squeeze()}\n",
    "            # update the embeddings\n",
    "            embeddings.append(embedding_dict[p]['emb'])\n",
    "\n",
    "    if embedding_model == 'cohere':\n",
    "        temp_embedding_dict = {p : {} for p in patents_list}\n",
    "        assert (type(cohere_client) == cohere.client.Client) or (type(cohere_client) == cohere.client_v2.ClientV2), \"undefined cohere client\"\n",
    "        assert cohere_model is not None, \"undefined cohere model\"\n",
    "        for p in patents_list:\n",
    "            if p not in embedding_dict.keys():\n",
    "                batch_patents.append(p)\n",
    "                if len(batch_patents) == batch_size:\n",
    "                    # get texts for this batch patents\n",
    "                    texts = [get_abstract(patent_id=p,patents_dict=patents_dict) for p in batch_patents]\n",
    "                    # use the cohere API to embed tham\n",
    "                    try:\n",
    "                        res = cohere_client.embed(texts=texts, model=cohere_model, input_type=\"classification\", embedding_types=[\"float\"])\n",
    "                    except RemoteProtocolError:\n",
    "                        print('cohere API error')\n",
    "                        return np.empty((1,)), False\n",
    "                    # update the temp dictionary\n",
    "                    for i in range(len(batch_patents)):\n",
    "                        temp_embedding_dict[batch_patents[i]] = {'emb' : res.embeddings.float_[i]}\n",
    "                        \n",
    "                    # restart the batch_patents list for the next batch\n",
    "                    batch_patents = []\n",
    "                \n",
    "            else:        \n",
    "                # we have an embedding for this patent in the embedding dict\n",
    "                temp_embedding_dict[p] = {'emb' : embedding_dict[p]['emb']}\n",
    "        \n",
    "        # if we embed in batches we might exit the loop over all patents when there are still patents to embed\n",
    "        if len(batch_patents) > 0:\n",
    "            # get texts for this batch patents\n",
    "            texts = [get_abstract(patent_id=p,patents_dict=patents_dict) for p in batch_patents]\n",
    "            # use the cohere API to embed tham\n",
    "            try:\n",
    "                res = cohere_client.embed(texts=texts, model=cohere_model, input_type=\"classification\", embedding_types=[\"float\"])\n",
    "            except RemoteProtocolError:\n",
    "                print('cohere API error')\n",
    "                return np.empty((1,)), False\n",
    "            # update the temp dictionary\n",
    "            for i in range(len(batch_patents)):\n",
    "                temp_embedding_dict[batch_patents[i]] = {'emb' : res.embeddings.float_[i]}\n",
    "\n",
    "        # at this points we should have embeddings for all patents in the input patents_list. copy them from the temp_embedding_dict to the global embedding_dict\n",
    "        # and update the embeddings\n",
    "        assert set(patents_list) == set(list(temp_embedding_dict.keys())), \"get_embeddings: temp_embedding_dict must have all input patents\"\n",
    "        for p in patents_list:\n",
    "            if p not in embedding_dict.keys():\n",
    "                embedding_dict[p] = {'emb' : temp_embedding_dict[p]['emb']}\n",
    "            \n",
    "            embeddings.append(embedding_dict[p]['emb'])\n",
    "        \n",
    "    return np.stack(embeddings, axis=0), True\n",
    "\n",
    "def get_abstract(patent_id: str, patents_dict: dict) -> str:\n",
    "    abstract = patents_dict[patent_id]['abstract']\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# building a tree dictionary - from codes to a list of all patents classified to that code (each patent may be assigned to few codes)\n",
    "# the dictionary is built hierarchic - first level of keys is first letter of the code, second level of keys is the next two digits etc.\n",
    "# the dict has 5 levels\n",
    "def get_codes_to_patent_mapping(patents_dict: dict):\n",
    "    codes_to_patent_mapping = {}\n",
    "    for k in patents_dict.keys():\n",
    "        for c in patents_dict[k]['cpcs']:\n",
    "            levels = parse_code_to_levels(c)\n",
    "            if levels[0] not in codes_to_patent_mapping.keys():\n",
    "                codes_to_patent_mapping[levels[0]] = {}\n",
    "\n",
    "            if levels[1] not in codes_to_patent_mapping[levels[0]].keys():\n",
    "                codes_to_patent_mapping[levels[0]][levels[1]] = {}\n",
    "\n",
    "            if levels[2] not in codes_to_patent_mapping[levels[0]][levels[1]].keys():\n",
    "                codes_to_patent_mapping[levels[0]][levels[1]][levels[2]] = {}\n",
    "\n",
    "            if levels[3] not in codes_to_patent_mapping[levels[0]][levels[1]][levels[2]].keys():\n",
    "                codes_to_patent_mapping[levels[0]][levels[1]][levels[2]][levels[3]] = {}\n",
    "\n",
    "            if levels[4] not in codes_to_patent_mapping[levels[0]][levels[1]][levels[2]][levels[3]].keys():\n",
    "                codes_to_patent_mapping[levels[0]][levels[1]][levels[2]][levels[3]][levels[4]] = [k]\n",
    "            else:\n",
    "                codes_to_patent_mapping[levels[0]][levels[1]][levels[2]][levels[3]][levels[4]].append(k)\n",
    "\n",
    "    return codes_to_patent_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Bert Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "embedding_file_path = os.path.join(datasets_dir,\"patent_bert_emb/PatentBert_emb_top100_cpc_class.json\")\n",
    "patents_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f = open(embedding_file_path)\n",
    "embedding_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"there are {len(embedding_dict)} patents in the dictionary\")\n",
    "print(embedding_dict[next(iter(embedding_dict))].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# looking at an example codes (labels) of a given entry\n",
    "print(embedding_dict[next(iter(embedding_dict))]['cpcs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Text (abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "patents_file_path = os.path.join(datasets_dir,\"patents_text/Patents/top100_cpc_class_abstract.json\")\n",
    "embedding_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "patents_dict = []\n",
    "with open(patents_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        patents_dict.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents_dict = {list(p.keys())[0] : list(p.values())[0] for p in patents_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"there are {len(patents_dict)} patents in the dictionary\")\n",
    "print(patents_dict[next(iter(patents_dict))].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_abstracts = [patents_dict[k]['abstract'] for k in patents_dict.keys()]\n",
    "print(f\"there are {len(all_abstracts)} abstracts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# get the distribution of sentences length\n",
    "abstracts_length = {i : len(all_abstracts[i].split()) for i in range(len(all_abstracts))}\n",
    "length_dist, bins = np.histogram(list(abstracts_length.values()),bins=50)\n",
    "bins = bins[:-1] + (bins[1] - bins[0])/2\n",
    "seq_len_fig = px.bar(x=bins, y=length_dist)\n",
    "seq_len_fig.update_layout(title='abstract length histogram', width=800)\n",
    "seq_len_fig.update_xaxes(title=\"length\")\n",
    "seq_len_fig.update_yaxes(title=\"count\")\n",
    "seq_len_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len = 32\n",
    "patents_dict = {k : v for k,v in patents_dict.items() if len(v['abstract'].split()) > min_len}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"there are {len(patents_dict)} patents in the dictionary\")\n",
    "print(patents_dict[next(iter(patents_dict))].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in patents_dict.keys():\n",
    "    patents_dict[k]['abstract']= patents_dict[k]['abstract'].replace(\"\\n\", \" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_abstracts = [patents_dict[k]['abstract'] for k in patents_dict.keys()]\n",
    "print(f\"there are {len(all_abstracts)} abstracts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# looking at an example codes (labels) of a given entry\n",
    "print(patents_dict[next(iter(patents_dict))]['cpcs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get OpenAI embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "key = ## YOUR KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "openai_tokens = [num_tokens_from_string(abstract,encoding) for abstract in all_abstracts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_tokens_price = 0.00002\n",
    "num_tokens = np.sum(openai_tokens)\n",
    "print(f\"num_tokens = {num_tokens}, num K tokens = {num_tokens/1000}, price = {(num_tokens/1000)*k_tokens_price}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"max number of tokens = {np.max(openai_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_id_abstract_tuples = [(k,patents_dict[k]['abstract']) for k in patents_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_batch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patent_id_abstract_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = \"text-embedding-3-small\"\n",
    "batch_size = 1500\n",
    "tokens_per_minute_limit = 1000000\n",
    "client = OpenAI(api_key=key)\n",
    "minute_tic = time.perf_counter()\n",
    "tokens_last_minute = 0\n",
    "for current_batch in range(10,145):\n",
    "    num_remaining_abstracts = len(patent_id_abstract_tuples) - current_batch*batch_size\n",
    "    if num_remaining_abstracts >= batch_size:\n",
    "        print(f\"getting {batch_size} embeddings\")\n",
    "        ids = [patent_id_abstract_tuples[current_batch*batch_size + i][0] for i in range(batch_size)]\n",
    "        text = [patent_id_abstract_tuples[current_batch*batch_size + i][1] for i in range(batch_size)]\n",
    "    else:\n",
    "        print(f\"getting {num_remaining_abstracts} embeddings\")\n",
    "        ids = [patent_id_abstract_tuples[current_batch*batch_size + i][0] for i in range(num_remaining_abstracts)]\n",
    "        text = [patent_id_abstract_tuples[current_batch*batch_size + i][1] for i in range(num_remaining_abstracts)]\n",
    "        \n",
    "    \n",
    "    if tokens_last_minute > tokens_per_minute_limit:\n",
    "        toc = time.perf_counter()\n",
    "        time.sleep(60)\n",
    "        print(f\"sleeping for {60} sec\")\n",
    "        minute_tic = time.perf_counter()\n",
    "        tokens_last_minute = 0\n",
    "    tokens_last_minute += np.sum([num_tokens_from_string(s,encoding) for s in text])\n",
    "    tic = time.perf_counter()\n",
    "    response = client.embeddings.create(input=text, model=embedding_model)\n",
    "    assert len(response.data) == len(ids), f\"batch {current_batch} response length must match input length\"\n",
    "    current_dict = {ids[i] : response.data[i].embedding for i in range(len(ids))}\n",
    "    file_name = os.path.join(datasets_dir,\"patents_text/openai_small_embeddings/\",f\"embedding_batch_{current_batch}.pkl\")\n",
    "    with open(file_name,'wb') as f:\n",
    "        pickle.dump(current_dict, f)\n",
    "    for i in range(len(ids)):\n",
    "        patents_dict[ids[i]]['emb'] = current_dict[ids[i]]\n",
    "    toc = time.perf_counter()\n",
    "    minute_timer = toc - minute_tic\n",
    "    if minute_timer >= 60:\n",
    "        minute_tic = time.perf_counter()\n",
    "        tokens_last_minute = 0\n",
    "    print(f\"batch {current_batch}: {toc - tic:0.4f} seconds passed \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.join(datasets_dir,\"patents_text/openai_small_embeddings/\",f\"all_embeddings.pkl\")\n",
    "with open(file_name,'wb') as f:\n",
    "    pickle.dump(patents_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ready embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case we already have embeddings in a file\n",
    "file_name = os.path.join(datasets_dir,\"patents_text/openai_large_embeddings/\",f\"all_embeddings.pkl\")\n",
    "with open(file_name,'rb') as f:\n",
    "    patents_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohere Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "from cohere import Client\n",
    "cohere_api_key = ## YOUR KEY\n",
    "cohere_trial_key = ## YOUR KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_trial_client = cohere.Client(cohere_trial_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cohere_trial_client) == cohere.client.Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohere_num_tokens_from_string(string: str, cohere_tokenizer) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    tokenized_str = cohere_tokenizer.encode(sequence=string, add_special_tokens=True)\n",
    "    return len(tokenized_str.tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer  \n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_prod_client = cohere.ClientV2(cohere_api_key)\n",
    "response = cohere_prod_client.models.list()\n",
    "response_dict = json.loads(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cohere_prod_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in response_dict['models']:\n",
    "    if model['name'] == 'embed-english-v3.0':\n",
    "        tokenizer_url = model['tokenizer_url']\n",
    "        print(f\"tokenizer_url = {tokenizer_url}\")\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the tokenizer locally\n",
    "response = requests.get(tokenizer_url)  \n",
    "cohere_tokenizer = Tokenizer.from_str(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_tokens = [cohere_num_tokens_from_string(abstract, cohere_tokenizer) for abstract in all_abstracts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_tokens_price = 0.1\n",
    "num_tokens = np.sum(cohere_tokens)\n",
    "print(f\"num_tokens = {num_tokens}, num 1M tokens = {num_tokens/1_000_000}, price = {(num_tokens/1_000_000)*M_tokens_price}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example embedding\n",
    "\n",
    "model = \"embed-english-v2.0\"\n",
    "input_type = \"classification\"\n",
    "t1 = time.perf_counter()\n",
    "res = cohere_trial_client.embed(texts=all_abstracts[:96],\n",
    "    model=model,\n",
    "    input_type=input_type,\n",
    "    embedding_types=[\"float\"],\n",
    ")\n",
    "t2 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_model = \"embed-english-v2.0\"\n",
    "cohere_embeddings_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res.embeddings.float_[90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## TF-IDF extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = [patents_dict[k]['abstract'] for k in patents_dict.keys()]\n",
    "print(f\"there are {len(abstracts)} abstracts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# represent each sentence as TF-IDF vector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "min_df = 50\n",
    "# if a term appears in more than 0.5 of documents, omit it\n",
    "max_df = 0.5\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=max_df, min_df=min_df, use_idf=True)\n",
    "abstract_vectorizer = tfidf_vectorizer.fit(abstracts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"number of stop words = {len(abstract_vectorizer.stop_words_)}\")\n",
    "print(f\"vocab size = {len(abstract_vectorizer.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained language models definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### XLnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import XLNetModel,AutoTokenizer\n",
    "\n",
    "xlnet_tokenizer = AutoTokenizer.from_pretrained(\"xlnet-large-cased\", cache_dir=models_dir)\n",
    "xlnet_model = XLNetModel.from_pretrained(\"xlnet-large-cased\", cache_dir=models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "embed_dim = xlnet_model.config.hidden_size\n",
    "print(f\"embedding dimension = {embed_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2Model\n",
    "model_name = 'gpt2'\n",
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=models_dir)\n",
    "gpt2_model = GPT2Model.from_pretrained(model_name, cache_dir=models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_model.embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_data = True\n",
    "idx = 1\n",
    "codes = experiments_codes['level_4'][idx]\n",
    "exp_patents = get_unique_patents_per_code(codes, codes_to_patent_mapping)\n",
    "min_num_samples = min([len(exp_patents[p]) for p in exp_patents.keys()])\n",
    "max_num_samples = 100\n",
    "# get the patents embeddings and arrange in an array\n",
    "X = []\n",
    "y = []\n",
    "j = 0\n",
    "for k in exp_patents.keys():\n",
    "    if embed_data:\n",
    "        curr_patents = get_abstracts(exp_patents[k], patents_dict)\n",
    "        curr_patents = resample(curr_patents, replace=False, n_samples=min_num_samples)\n",
    "        if len(curr_patents) > max_num_samples:\n",
    "            curr_patents = resample(curr_patents, replace=False, n_samples=max_num_samples)\n",
    "        X.extend(curr_patents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = xlnet_tokenizer(X[:1], truncation=True, padding=True, max_length=max_length,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "output = xlnet_model(**input)\n",
    "toc = time.perf_counter()\n",
    "print(f\"so far, {toc - tic:0.4f} seconds passed \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "tic = time.perf_counter()\n",
    "batch_size = 1\n",
    "input = gpt2_tokenizer(X[6:6+batch_size], truncation=True, padding=True, max_length=max_length,return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    output = gpt2_model(**input)\n",
    "    # with GPT2 embeddings, we take the mean of the hidden states of all tokens\n",
    "    #gpt2_embeddings[i,:] = output.last_hidden_state[:,:,:].numpy().mean(axis=1)\n",
    "    #gpt2_embeddings[i,:] = output.last_hidden_state[:,-1,:].numpy()\n",
    "toc = time.perf_counter()\n",
    "inference_time = toc - tic\n",
    "print(f\"so far, {inference_time:0.4f} seconds passed \\n\\n\")\n",
    "print(f\"inference time per sentence =  {inference_time/batch_size:0.4f} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract codes for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def validate_min_samples(codes, required_samples_num, codes_list, codes_to_patent_mapping):\n",
    "    curr_codes_patents = get_unique_patents_per_code(codes, codes_to_patent_mapping)\n",
    "    # get the class with minimal number of patents, and down sample the rest of the classes to this size\n",
    "    num_samples = min([len(curr_codes_patents[p]) for p in curr_codes_patents.keys()])\n",
    "    if num_samples > required_samples_num:\n",
    "        codes_list.append(codes)\n",
    "    return codes_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_to_patent_mapping = get_codes_to_patent_mapping(patents_dict=patents_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_experiments = 50\n",
    "num_classes = 3\n",
    "required_samples_num = 100\n",
    "experiments_codes = {f'level_{i}' : [] for i in range(1,6)}\n",
    "\n",
    "# generate codes for level 1\n",
    "all_first_level_codes = list(codes_to_patent_mapping.keys())\n",
    "assert num_classes <= len(all_first_level_codes), \"number off classes cannot exceed number of possible codes\"\n",
    "while len(experiments_codes['level_1']) < num_experiments:\n",
    "    codes = sample(all_first_level_codes, num_classes)\n",
    "    experiments_codes['level_1'] = validate_min_samples(codes, required_samples_num, experiments_codes['level_1'], codes_to_patent_mapping)\n",
    "\n",
    "\n",
    "\n",
    "# generate codes for level 2\n",
    "while len(experiments_codes['level_2']) < num_experiments:\n",
    "    # generate codes for current experiment\n",
    "    first_level_code = sample(all_first_level_codes, 1)[0]\n",
    "    second_level_pool = list(codes_to_patent_mapping[first_level_code].keys())\n",
    "    if len(second_level_pool) < num_classes:\n",
    "        continue\n",
    "    second_level_codes = sample(second_level_pool,num_classes)\n",
    "    codes = [(first_level_code,c) for c in second_level_codes]\n",
    "    experiments_codes['level_2'] = validate_min_samples(codes, required_samples_num, experiments_codes['level_2'], codes_to_patent_mapping)\n",
    "\n",
    "\n",
    "# generate codes for level 3\n",
    "while len(experiments_codes['level_3']) < num_experiments:\n",
    "    # generate codes for current experiment\n",
    "    first_level_code = sample(all_first_level_codes, 1)[0]\n",
    "    second_level_pool = list(codes_to_patent_mapping[first_level_code].keys())\n",
    "    if len(second_level_pool) < num_classes:\n",
    "        continue\n",
    "    second_level_code = sample(second_level_pool,1)[0]\n",
    "    third_level_pool = list(codes_to_patent_mapping[first_level_code][second_level_code].keys())\n",
    "    if len(third_level_pool) < num_classes:\n",
    "        continue\n",
    "    third_level_codes = sample(third_level_pool,num_classes)\n",
    "    codes = [(first_level_code, second_level_code, c) for c in third_level_codes]\n",
    "    experiments_codes['level_3'] = validate_min_samples(codes, required_samples_num, experiments_codes['level_3'], codes_to_patent_mapping)\n",
    "\n",
    "\n",
    "# generate codes for level 4\n",
    "while len(experiments_codes['level_4']) < num_experiments:\n",
    "    # generate codes for current experiment\n",
    "    first_level_code = sample(all_first_level_codes, 1)[0]\n",
    "    second_level_pool = list(codes_to_patent_mapping[first_level_code].keys())\n",
    "    if len(second_level_pool) < num_classes:\n",
    "        continue\n",
    "    second_level_code = sample(second_level_pool,1)[0]\n",
    "    third_level_pool = list(codes_to_patent_mapping[first_level_code][second_level_code].keys())\n",
    "    if len(third_level_pool) < num_classes:\n",
    "        continue\n",
    "    third_level_code = sample(third_level_pool,1)[0]\n",
    "    four_level_pool = list(codes_to_patent_mapping[first_level_code][second_level_code][third_level_code].keys())\n",
    "    if len(four_level_pool) < num_classes:\n",
    "        continue\n",
    "    four_level_codes = sample(four_level_pool,num_classes)\n",
    "    codes = [(first_level_code, second_level_code, third_level_code, c) for c in four_level_codes]\n",
    "    experiments_codes['level_4'] = validate_min_samples(codes, required_samples_num, experiments_codes['level_4'], codes_to_patent_mapping)\n",
    "\n",
    "# generate codes for level 5\n",
    "while len(experiments_codes['level_5']) < num_experiments:\n",
    "    # generate codes for current experiment\n",
    "    first_level_code = sample(all_first_level_codes, 1)[0]\n",
    "    second_level_pool = list(codes_to_patent_mapping[first_level_code].keys())\n",
    "    if len(second_level_pool) < 1:\n",
    "        continue\n",
    "    second_level_code = sample(second_level_pool,1)[0]\n",
    "    third_level_pool = list(codes_to_patent_mapping[first_level_code][second_level_code].keys())\n",
    "    if len(third_level_pool) < 1:\n",
    "        continue\n",
    "    third_level_code = sample(third_level_pool,1)[0]\n",
    "    four_level_pool = list(codes_to_patent_mapping[first_level_code][second_level_code][third_level_code].keys())\n",
    "    if len(four_level_pool) < 1:\n",
    "        continue\n",
    "    four_level_code = sample(four_level_pool,1)[0]\n",
    "    fifth_level_pool = list(codes_to_patent_mapping[first_level_code][second_level_code][third_level_code][four_level_code].keys())\n",
    "    if len(fifth_level_pool) < num_classes:\n",
    "        continue\n",
    "\n",
    "    fifth_level_codes = sample(fifth_level_pool,num_classes)\n",
    "    codes = [(first_level_code, second_level_code, third_level_code, four_level_code, c) for c in fifth_level_codes]\n",
    "    experiments_codes['level_5'] = validate_min_samples(codes, required_samples_num, experiments_codes['level_5'], codes_to_patent_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check that all levels have codes\n",
    "for level in experiments_codes.keys():\n",
    "    print(f\"{level} has {len(experiments_codes[level])} codes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# classification experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "num_spc = 30 # number of train samples per class\n",
    "num_experiments_in_code = 3 # for each set of codes (dataset with labels) repeat the experiment with different train/test splits\n",
    "feature_dim = 4096 #1536\n",
    "\n",
    "\n",
    "beta = 0.3\n",
    "gamma = feature_dim**(-beta)\n",
    "print(f\"gamma = {gamma}, max num features = {int(feature_dim*gamma)}\")\n",
    "verbosity = False\n",
    "hc_stbl = False\n",
    "hc_method = 'jin'\n",
    "use_emp_cdf_in_hc_obj = False\n",
    "override_inf_nan_stat = False\n",
    "dp_fs_anova = FeatureSelectionDiversityPursuitAnova(hc_gamma=gamma,\n",
    "                                                    hc_stbl=hc_stbl,\n",
    "                                                    hc_method=hc_method,\n",
    "                                                    use_emp_cdf_in_hc_obj=False,\n",
    "                                                    override_inf_nan_stat=override_inf_nan_stat,\n",
    "                                                    transformer=None, verbosity=verbosity)\n",
    "\n",
    "dp_fs_k_anova = FeatureSelectionDiversityPursuitKruskal(hc_gamma=gamma,\n",
    "                                                    hc_stbl=hc_stbl,\n",
    "                                                    hc_method=hc_method,\n",
    "                                                    use_emp_cdf_in_hc_obj=False,\n",
    "                                                    override_inf_nan_stat=override_inf_nan_stat,\n",
    "                                                    transformer=None, verbosity=verbosity)\n",
    "\n",
    "\n",
    "ova_fs_ks = FeatureSelectionOneVsAllKS(hc_gamma=gamma, \n",
    "                                       hc_stbl=hc_stbl, \n",
    "                                       hc_method=hc_method,\n",
    "                                       use_emp_cdf_in_hc_obj=False,\n",
    "                                       override_inf_nan_stat=override_inf_nan_stat,\n",
    "                                       transformer=None, verbosity=verbosity)\n",
    "ova_fs_t_test = FeatureSelectionOneVsAllAnova(hc_gamma=gamma, \n",
    "                                              hc_stbl=hc_stbl, \n",
    "                                              hc_method=hc_method,\n",
    "                                              use_emp_cdf_in_hc_obj=False,\n",
    "                                              override_inf_nan_stat=override_inf_nan_stat,\n",
    "                                              transformer=None, verbosity=verbosity)\n",
    "\n",
    "\n",
    "c_grid = [0.001,0.01,0.1,1,10,100]\n",
    "svm_kernel_grid = ['linear', 'rbf', 'poly']\n",
    "max_iter = [700]\n",
    "svm_tol = [5e-3]\n",
    "svm_with_feat_sel_pipe = Pipeline([('scaling', StandardScaler()), ('clf', LinearSVC())])\n",
    "svm_with_feat_sel_pipe_parameters = dict(scaling=['passthrough', StandardScaler()],\n",
    "                                         clf__C=c_grid,\n",
    "                                         clf__penalty=['l1'],\n",
    "                                         clf__dual=['auto'],\n",
    "                                         #clf__kernel=svm_kernel_grid,\n",
    "                                         clf__max_iter=max_iter,\n",
    "                                         clf__tol=svm_tol)\n",
    "\n",
    "svm_without_feat_sel_pipe = Pipeline([('scaling', StandardScaler()), ('clf', SVC())])\n",
    "svm_without_feat_sel_pipe_parameters = dict(scaling=['passthrough', StandardScaler()],\n",
    "                                         clf__C=c_grid,\n",
    "                                         clf__kernel=svm_kernel_grid,\n",
    "                                         clf__max_iter=max_iter,\n",
    "                                         clf__tol=svm_tol)\n",
    "\n",
    "log_reg_pipe = Pipeline([('scaling', StandardScaler()), ('clf', LogisticRegression())])\n",
    "log_reg_pipe_parameters = {'scaling' : ['passthrough', StandardScaler()],\n",
    "                           'clf__C' : c_grid,\n",
    "                           'clf__penalty' : ['l1'],\n",
    "                           'clf__solver' : ['liblinear'],\n",
    "                           'clf__max_iter' : max_iter,\n",
    "                           'clf__tol' : [5e-4]}\n",
    "\n",
    "\n",
    "log_reg_fs_pipe = Pipeline([('scaling', StandardScaler()), ('clf', LogisticRegression())])\n",
    "log_reg_fs_pipe_parameters = {'scaling' : ['passthrough', StandardScaler()],\n",
    "                           'clf__penalty' : [None],\n",
    "                           'clf__max_iter' : max_iter,\n",
    "                           'clf__tol' : [5e-4]}\n",
    "\n",
    "\n",
    "svm_fs_pipe = Pipeline([('scaling', StandardScaler()), ('clf', SVC())])\n",
    "svm_fs_pipe_parameters = dict(scaling=['passthrough', StandardScaler()],\n",
    "                                         clf__C=c_grid,\n",
    "                                         clf__kernel=svm_kernel_grid,\n",
    "                                         clf__max_iter=max_iter,\n",
    "                                         clf__tol=svm_tol)\n",
    "\n",
    "n_estimators_grid = [10,20,50,100]\n",
    "max_depth_grid = [3,5,7]\n",
    "learning_rate_grid = [0.05, 0.1, 0.3]\n",
    "gb_cls_parameters = {'learning_rate' : learning_rate_grid, 'n_estimators' : n_estimators_grid, 'max_depth' : max_depth_grid}\n",
    "gb_cls = GradientBoostingClassifier()\n",
    "rf_cls_parameters = {'n_estimators' : n_estimators_grid, 'max_depth' : max_depth_grid}\n",
    "rf_cls = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# defining classifiers\n",
    "use_euclidian_distance = False\n",
    "cs_cls  = CentroidSimilarity(use_euclidian_distance=use_euclidian_distance)\n",
    "cs_fs_dp = ClassifierFeatureSelection(CentroidSimilarity(use_euclidian_distance=use_euclidian_distance), dp_fs_anova)\n",
    "cs_fs_ova = ClassifierFeatureSelection(CentroidSimilarity(use_euclidian_distance=use_euclidian_distance), ova_fs_t_test)\n",
    "cs_fs_ova_ks = ClassifierFeatureSelection(CentroidSimilarity(use_euclidian_distance=use_euclidian_distance), ova_fs_ks)\n",
    "num_classifiers = 5 # including base classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#max_num_samples = 3*required_samples_num\n",
    "noise_std = 0.01\n",
    "levels_to_visualize = ['level_3', 'level_4', 'level_5']\n",
    "exp_codes = []\n",
    "code_num_feat = []\n",
    "code_acc = []\n",
    "for level in levels_to_visualize:    #experiments_codes.keys():\n",
    "    print(f\"classification in {level}\")\n",
    "    print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    exp_cnt = 0\n",
    "    for codes in experiments_codes[level]:\n",
    "        exp_patents = get_unique_patents_per_code(codes, codes_to_patent_mapping)\n",
    "        exp_cnt += 1\n",
    "        print(f\"running exp {exp_cnt}\")\n",
    "        print(f\"selected codes = {codes}\")\n",
    "        min_num_samples = min([len(exp_patents[p]) for p in exp_patents.keys()])\n",
    "        print(f\"min num samples = {min_num_samples}\")\n",
    "        # get the patents embeddings and arrange in an array\n",
    "        X = []\n",
    "        y = []\n",
    "        j = 0\n",
    "        for k in exp_patents.keys():\n",
    "            #curr_patents = resample(curr_patents, replace=False, n_samples=min_num_samples)\n",
    "            if len(exp_patents[k]) > required_samples_num:\n",
    "                curr_patents = resample(exp_patents[k], replace=False, n_samples=required_samples_num)\n",
    "            else:\n",
    "                curr_patents = exp_patents[k].copy()\n",
    "                \n",
    "            curr_embeddings, valid_embeddings = get_embeddings(patents_list=curr_patents, patents_dict=patents_dict, embedding_model='cohere', embedding_dict=cohere_embeddings_dict, cohere_client=cohere_prod_client, cohere_model=cohere_model)\n",
    "            if not valid_embeddings:\n",
    "                break\n",
    "            X.append(curr_embeddings)\n",
    "            y.append(j * np.ones((curr_embeddings.shape[0],)))\n",
    "            j += 1\n",
    "        if not valid_embeddings:\n",
    "            print('skipping experiment - failed to obtain embeddings')\n",
    "            continue\n",
    "        X = np.concatenate(X, axis=0)\n",
    "        y = np.concatenate(y, axis=0)\n",
    "        print(f\"X shape = {X.shape}\")\n",
    "        print(f\"y shape = {y.shape}\")\n",
    "        # add random noise\n",
    "        X = X + noise_std * np.random.randn(*(X.shape))\n",
    "        accuracies = np.empty((num_classifiers, num_experiments_in_code))\n",
    "        num_features = np.empty_like(accuracies)\n",
    "        for i in range(num_experiments_in_code):\n",
    "            # split to train and test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=num_spc*num_classes, stratify=y)\n",
    "            # tune the SVM classifier using the train data\n",
    "            num_splits = min(num_spc,5)\n",
    "            skf = StratifiedKFold(n_splits=num_splits)\n",
    "            \n",
    "            #svm_with_feat_sel_search = GridSearchCV(svm_with_feat_sel_pipe, svm_with_feat_sel_pipe_parameters, cv=skf, scoring='accuracy', n_jobs=4)\n",
    "            #svm_with_feat_sel_search.fit(X_train, y_train)\n",
    "            #svm_with_feat_sel_best = svm_with_feat_sel_search.best_estimator_\n",
    "            #print(f\"best SVM with feat sel grid search score = {svm_with_feat_sel_search.best_score_}\")\n",
    "\n",
    "            svm_without_feat_sel_search = GridSearchCV(svm_without_feat_sel_pipe, svm_without_feat_sel_pipe_parameters, cv=skf, scoring='accuracy', n_jobs=4)\n",
    "            svm_without_feat_sel_search.fit(X_train, y_train)\n",
    "            svm_without_feat_sel_best = svm_without_feat_sel_search.best_estimator_\n",
    "            print(f\"best SVM without feat sel grid search score = {svm_without_feat_sel_search.best_score_}\")\n",
    "\n",
    "            log_reg_search = GridSearchCV(log_reg_pipe, log_reg_pipe_parameters, cv=skf, scoring='accuracy', n_jobs=4)\n",
    "            log_reg_search.fit(X_train, y_train)\n",
    "            log_reg_best = log_reg_search.best_estimator_\n",
    "            print(f\"best LASSO grid search score = {log_reg_search.best_score_}\")\n",
    "\n",
    "            \n",
    "            #X_train_fs = dp_fs_k_anova.fit_transform(X_train, y_train)\n",
    "            # SVM with HC-ANOVA feature selection grid search\n",
    "            #svm_fs_search = GridSearchCV(svm_fs_pipe, svm_fs_pipe_parameters, cv=skf, scoring='accuracy', n_jobs=4)\n",
    "            #svm_fs_search.fit(X_train_fs, y_train)\n",
    "            #svm_fs_best = Pipeline([('feat_sel', dp_fs_k_anova), ('clf', svm_fs_search.best_estimator_)])\n",
    "            #print(f\"best SVM with HC-ANOVA feature selection grid search score = {svm_fs_search.best_score_}\")\n",
    "\n",
    "            # Log Reg with HC-ANOVA feature selection grid search\n",
    "            #log_reg_fs_search = GridSearchCV(log_reg_fs_pipe, log_reg_fs_pipe_parameters, cv=skf, scoring='accuracy', n_jobs=4)\n",
    "            #log_reg_fs_search.fit(X_train_fs, y_train)\n",
    "            #log_reg_fs_best = Pipeline([('feat_sel', dp_fs_k_anova), ('clf', log_reg_fs_search.best_estimator_)])\n",
    "            #print(f\"best Logistic regression with HC-ANOVA feature selection grid search score = {log_reg_fs_search.best_score_}\")\n",
    "\n",
    "            #gb_search = GridSearchCV(gb_cls, gb_cls_parameters, cv=skf, scoring='accuracy', n_jobs=4)\n",
    "            #gb_search.fit(X_train, y_train)\n",
    "            #gb_best = gb_search.best_estimator_\n",
    "            #print(f\"best Grad boost grid search score = {gb_search.best_score_}\")\n",
    "\n",
    "            #rf_search = GridSearchCV(rf_cls, rf_cls_parameters, cv=skf, scoring='accuracy', n_jobs=4)\n",
    "            #rf_search.fit(X_train, y_train)\n",
    "            #rf_best = rf_search.best_estimator_\n",
    "            #print(f\"best random forest grid search score = {rf_search.best_score_}\")\n",
    "\n",
    "            classifiers = [cs_cls,  cs_fs_dp,   cs_fs_ova,   svm_without_feat_sel_best,  log_reg_best]\n",
    "            cls_names = ['cs_all', 'cs_fs_dp', 'cs_fs_ova',  'svm_without_feat_sel'    , 'log_reg']\n",
    "\n",
    "            #classifiers = [svm_without_feat_sel_best, log_reg_best, svm_fs_best, log_reg_fs_best]\n",
    "            #cls_names = ['SVM', 'log reg Lasso', 'SVM HC ANOVA', 'Log Reg HC ANOVA']\n",
    "\n",
    "\n",
    "            accuracies[:, i], num_features[:, i] = multiple_classifiers_fit_predict(classifiers=classifiers,\n",
    "                                                                                    X_train=X_train,\n",
    "                                                                                    y_train=y_train,\n",
    "                                                                                    X_test=X_test,\n",
    "                                                                                    y_test=y_test,\n",
    "                                                                                    score_func=accuracy_score,\n",
    "                                                                                    preprocess_func=None,\n",
    "                                                                                    get_features=False,\n",
    "                                                                                    scaler_func=None)\n",
    "            \n",
    "\n",
    "        \n",
    "        # get the average accuracy for the current code\n",
    "        mean_acc = np.squeeze(np.mean(accuracies,axis=1))\n",
    "        print(f\"mean accuracies: \\n  {[f'{k}:{v}' for (k,v) in dict(zip(cls_names,list(mean_acc))).items()]}\")\n",
    "        mean_num_features = np.squeeze(np.mean(num_features,axis=1))\n",
    "        print(f\"mean num features: \\n  {[f'{k}:{v}' for (k,v) in dict(zip(cls_names,list(mean_num_features))).items()]}\")\n",
    "        # store the results\n",
    "        code_acc.append(accuracies)\n",
    "        code_num_feat.append(num_features)\n",
    "        exp_codes.append(tuple(codes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "code_acc_all_exp = np.stack(code_acc,axis=0)\n",
    "code_acc_all_exp = np.squeeze(np.mean(code_acc_all_exp,axis=2))\n",
    "code_num_feat_all_exp = np.stack(code_num_feat,axis=0)\n",
    "code_num_feat_all_exp = np.squeeze(np.mean(code_num_feat_all_exp,axis=2))\n",
    "code_acc_all_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "code_acc_all_exp = pd.DataFrame({cls_names[i] : code_acc_all_exp[:,i] for i in range(len(cls_names))})\n",
    "code_acc_all_exp['codes'] = exp_codes\n",
    "exp_level = [len(exp_codes[i][0]) for i in range(len(exp_codes))]\n",
    "code_acc_all_exp['exp_level'] = exp_level\n",
    "code_acc_all_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "code_num_features_all_exp = pd.DataFrame({cls_names[i] : code_num_feat_all_exp[:,i] for i in range(len(cls_names))})\n",
    "code_num_features_all_exp['codes'] = exp_codes\n",
    "code_num_features_all_exp['exp_level'] = exp_level\n",
    "code_num_features_all_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "figures = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gb = code_acc_all_exp.drop('codes',axis=1).groupby('exp_level').mean()\n",
    "cols = list(gb)\n",
    "gb['exp_level'] = gb.index\n",
    "acc_fig = px.bar(gb, x='exp_level', y=cols)\n",
    "acc_fig.update_layout(barmode='group', title='classifiers accuracy over code levels')\n",
    "acc_fig.update_yaxes({'title' : 'accuracy'})\n",
    "acc_fig.show()\n",
    "figures.append(acc_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gb = code_num_features_all_exp.drop('codes',axis=1).groupby('exp_level').mean()\n",
    "cols = list(gb)\n",
    "gb['exp_level'] = gb.index\n",
    "fig = px.bar(gb, x='exp_level', y=cols)\n",
    "fig.update_layout(barmode='group', title='classifiers mean num features over code levels')\n",
    "fig.update_yaxes({'title' : 'num features'})\n",
    "fig.show()\n",
    "figures.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"total patents embedded = {len(cohere_embeddings_dict)}\")\n",
    "embeddings_dir = os.path.join(datasets_dir,f\"patents_text/cohere_{cohere_model}_embeddings/\")\n",
    "if os.path.isdir(embeddings_dir) is not True:\n",
    "    os.mkdir(embeddings_dir)\n",
    "    print(\"making dir for embeddings\")\n",
    "file_name = os.path.join(embeddings_dir,f\"all_embeddings.pkl\")\n",
    "with open(file_name,'wb') as f:\n",
    "    pickle.dump(cohere_embeddings_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_embeddings(curr_patents: list, embedding_dict: dict):\n",
    "    embeddings = []\n",
    "    for p in curr_patents:\n",
    "        if p in embedding_dict.keys():\n",
    "            embeddings.append(embedding_dict[p]['emb'])\n",
    "        else:\n",
    "            continue\n",
    "    return np.stack(embeddings, axis=0)\n",
    " \n",
    "levels = ['level_3', 'level_4', 'level_5']\n",
    "level_distances = {l : [] for l in levels}\n",
    "for level in levels:\n",
    "    \n",
    "    for codes in experiments_codes[level]:\n",
    "        exp_patents = get_unique_patents_per_code(codes, codes_to_patent_mapping)\n",
    "        # get the patents embeddings for each code (class) and compute the class mean\n",
    "        means = []\n",
    "        #print(exp_patents.keys())\n",
    "        for k in exp_patents.keys():\n",
    "            if len(exp_patents[k]) > 1000:\n",
    "                curr_patents = resample(exp_patents[k], replace=False, n_samples=1000)\n",
    "            else:\n",
    "                curr_patents = exp_patents[k].copy()\n",
    "            curr_embeddings = get_available_embeddings(curr_patents=curr_patents, embedding_dict=cohere_embeddings_dict)\n",
    "            class_mean = curr_embeddings.mean(axis=0)\n",
    "            means.append(class_mean)\n",
    "        # Stack vectors into a 2D numpy\n",
    "        means = np.vstack(means)\n",
    "        # Compute pairwise Euclidean distances\n",
    "        distances = cdist(means, means, metric='euclidean')\n",
    "        upper_tri_indices = np.triu_indices(len(means), k=1)\n",
    "        # Extract the upper triangular elements using these indices\n",
    "        upper_triangle_distances = distances[upper_tri_indices]\n",
    "        for d in upper_triangle_distances:\n",
    "            level_distances[level].append(d)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_distances_hist = {k : np.histogram(level_distances[k], bins=10) for k in level_distances.keys()}\n",
    "level_names_dict = {'level_3' : 'sub-class level',\n",
    "                    'level_4' : 'group level',\n",
    "                    'level_5' : 'sub-group level'}\n",
    "level_distances_hist\n",
    "fig = go.Figure(data=[go.Bar(x=level_distances_hist[k][1][:-1], y=level_distances_hist[k][0], name=level_names_dict[k], opacity=0.75) for k in level_distances_hist.keys()])\n",
    "fig.update_layout(\n",
    "        #legend = dict(font=dict(size=20)),\n",
    "        font = dict(size=20),\n",
    "        #legend_font_size = 20,\n",
    "        #xaxis_title_font_size = 20,\n",
    "        xaxis_title='Distance',\n",
    "        yaxis_title='Count',\n",
    "        barmode='overlay',  # Overlay histograms to compare\n",
    "        template='plotly',\n",
    "        bargap=0.2\n",
    "    )\n",
    "fig.show()\n",
    "#figures.append(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def add_local_dicts_to_run_params(run_params: dict, local_dict: dict, local_dict_name: str):\n",
    "    for k in local_dict.keys():\n",
    "        run_params[f'{local_dict_name}__{k}'] = local_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create a folder to hold the experiment artifacts (files)\n",
    "cwd=os.getcwd()\n",
    "artifacts_dir = os.path.join(cwd,'run_artifacts')\n",
    "print(f\"artifacts dir = {artifacts_dir}\")\n",
    "if os.path.isdir(artifacts_dir) is not True:\n",
    "    os.mkdir(artifacts_dir)\n",
    "else:\n",
    "    if os.listdir(artifacts_dir):\n",
    "        # remove all files\n",
    "        print(\"cleaning artifacts dir\")\n",
    "        for file in os.listdir(artifacts_dir):\n",
    "            os.remove(os.path.join(artifacts_dir,file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "experiment = mlflow.set_experiment(experiment_name=\"Patent embedding classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "experiment_id = experiment.experiment_id\n",
    "print(f\"experiment_id = {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "run_name = f\"run_3_levels_cohere_large_embed\"\n",
    "print(f\"run_name = {run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "code_num_features_all_exp.to_csv(os.path.join(artifacts_dir,'num_features_all_exp.csv'))\n",
    "code_acc_all_exp.to_csv(os.path.join(artifacts_dir,'acc_all_exp.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from utils.experiment_utils import gen_html_report\n",
    "gen_html_report(html_path=os.path.join(artifacts_dir,'figures.html'),items=figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "description = f'perform classification over 3 levels of codes. from each level, sample {num_experiments} sets of {num_classes} codes. the problem is a multi-class classification of {num_classes} classes. for each set, perform {num_experiments_in_code} experiments. in each experiment, perform a grid search to find the best tuning for the base classifiers in the experiment. '\n",
    "            \n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "run_params = {\n",
    "    'num_classes' : num_classes,\n",
    "    'num_spc' : num_spc,\n",
    "    'required_samples_num':required_samples_num,\n",
    "    'hc_stbl' : hc_stbl,\n",
    "    'hc_method': hc_method,\n",
    "    'hc_gamma' : gamma,\n",
    "    'num_experiments' : num_experiments,\n",
    "    'num_experiments_in_code' : num_experiments_in_code\n",
    "}\n",
    "\n",
    "add_local_dicts_to_run_params(run_params, svm_without_feat_sel_pipe_parameters, 'svm_without_feat_sel_pipe_parameters')\n",
    "add_local_dicts_to_run_params(run_params, svm_with_feat_sel_pipe_parameters, 'svm_with_feat_sel_pipe_parameters')\n",
    "add_local_dicts_to_run_params(run_params, log_reg_pipe_parameters, 'log_reg_pipe_parameters')\n",
    "print(run_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "curr_run = mlflow.start_run(experiment_id=experiment_id, run_name=run_name, description=description)\n",
    "mlflow.log_params(run_params)\n",
    "mlflow.log_artifact(local_path=artifacts_dir)\n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Observe P-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#fs_scaler = StandardScaler(with_mean=False)\n",
    "#fs_scaler = PowerTransformer(standardize=False)\n",
    "fs_scaler = None\n",
    "dp_fs_anova = FeatureSelectionDiversityPursuitAnova(hc_gamma=0.8, hc_stbl=False, hc_method='jin', use_emp_cdf_in_hc_obj=use_emp_cdf_in_hc_obj, transformer=fs_scaler, verbosity=True)\n",
    "dp_fs_anova.fit(X_train, y_train)\n",
    "print(f\"feature selector hct = {dp_fs_anova.hct}\")\n",
    "print(f\"num selected features = {dp_fs_anova.get_num_selected_features()}\")\n",
    "mi_hist, bins = np.histogram(dp_fs_anova.pvals, bins=100)\n",
    "bins = bins[:-1] + (bins[1] - bins[0]) / 2\n",
    "fig = px.bar(x=bins, y=mi_hist)\n",
    "fig.update_layout(title='pval histogram', width=800)\n",
    "fig.update_xaxes(title=\"p-val\")\n",
    "fig.update_yaxes(title=\"count\")\n",
    "fig.show()\n",
    "X_cov = np.corrcoef(X_train, rowvar=False)\n",
    "print(f\"X_cov.shape = {X_cov.shape}\")\n",
    "fig = px.imshow(X_cov)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from random import sample\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_codes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_for_vis = {f'level_{i}' : [] for i in range(1,6)}\n",
    "\n",
    "while (len(codes_for_vis['level_5']) < 1) or (len(codes_for_vis['level_4']) < 1) or (len(codes_for_vis['level_3']) < 1):\n",
    "    # generate codes for current experiment\n",
    "    first_level_code = sample(all_first_level_codes, 1)[0]\n",
    "    codes_for_vis['level_1'] = first_level_code\n",
    "    second_level_pool = list(codes_to_patent_mapping[first_level_code].keys())\n",
    "    if len(second_level_pool) < 1:\n",
    "        codes_for_vis = {f'level_{i}' : [] for i in range(1,6)}\n",
    "        continue\n",
    "    second_level_code = sample(second_level_pool,1)[0]\n",
    "    codes_for_vis['level_2'] = second_level_code\n",
    "    third_level_pool = list(codes_to_patent_mapping[first_level_code][second_level_code].keys())\n",
    "    if len(third_level_pool) < num_classes:\n",
    "        codes_for_vis = {f'level_{i}' : [] for i in range(1,6)}\n",
    "        continue\n",
    "    third_level_codes = sample(third_level_pool,num_classes)\n",
    "    codes = [(first_level_code, second_level_code, c) for c in third_level_codes]\n",
    "    codes_for_vis['level_3'] = validate_min_samples(codes, required_samples_num, codes_for_vis['level_3'], codes_to_patent_mapping)\n",
    "    third_level_code = third_level_codes[0]\n",
    "    four_level_pool = list(codes_to_patent_mapping[first_level_code][second_level_code][third_level_code].keys())\n",
    "    if len(four_level_pool) < num_classes:\n",
    "        codes_for_vis = {f'level_{i}' : [] for i in range(1,6)}\n",
    "        continue\n",
    "    four_level_codes = sample(four_level_pool,num_classes)\n",
    "    four_level_code = four_level_codes[0]\n",
    "    codes = [(first_level_code, second_level_code, third_level_code, c) for c in four_level_codes]\n",
    "    codes_for_vis['level_4'] = validate_min_samples(codes, required_samples_num, codes_for_vis['level_4'], codes_to_patent_mapping)\n",
    "    fifth_level_pool = list(codes_to_patent_mapping[first_level_code][second_level_code][third_level_code][four_level_code].keys())\n",
    "    if len(fifth_level_pool) < num_classes:\n",
    "        codes_for_vis = {f'level_{i}' : [] for i in range(1,6)}\n",
    "        continue\n",
    "\n",
    "    fifth_level_codes = sample(fifth_level_pool,num_classes)\n",
    "    \n",
    "    codes = [(first_level_code, second_level_code, third_level_code, four_level_code, c) for c in fifth_level_codes]\n",
    "    codes_for_vis['level_5'] = validate_min_samples(codes, required_samples_num, codes_for_vis['level_5'], codes_to_patent_mapping)\n",
    "    #experiments_codes['level_5'] = validate_min_samples(codes, required_samples_num, experiments_codes['level_5'], codes_to_patent_mapping)\n",
    "\n",
    "codes_for_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_samples_num = 300\n",
    "levels_to_visualize = ['level_3', 'level_4', 'level_5']\n",
    "tsne_fig = make_subplots(rows=len(levels_to_visualize), cols=1,shared_xaxes=True)\n",
    "\n",
    "p = 5\n",
    "distances = {}\n",
    "for i,level in enumerate(levels_to_visualize):\n",
    "    codes = sample(codes_for_vis[level],1)[0]\n",
    "    print(f\"selected codes = {codes}\")\n",
    "    exp_patents = get_unique_patents_per_code(codes, codes_to_patent_mapping)\n",
    "    min_num_samples = min([len(exp_patents[p]) for p in exp_patents.keys()])\n",
    "    print(f\"min num samples = {min_num_samples}\")\n",
    "    # get the patents embeddings and arrange in an array\n",
    "    X = []\n",
    "    y = []\n",
    "    j = 0\n",
    "    for k in exp_patents.keys():\n",
    "        #curr_patents = resample(curr_patents, replace=False, n_samples=min_num_samples)\n",
    "        if len(exp_patents[k]) > required_samples_num:\n",
    "            curr_patents = resample(exp_patents[k], replace=False, n_samples=required_samples_num)\n",
    "        else:\n",
    "            curr_patents = exp_patents[k].copy()      \n",
    "        curr_embeddings = get_embeddings(patents_list=curr_patents, patents_dict=patents_dict, embedding_dict=patents_dict)\n",
    "        X.append(curr_embeddings)\n",
    "        y.append(j * np.ones((curr_embeddings.shape[0],)))\n",
    "        j += 1\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    y = np.concatenate(y, axis=0)\n",
    "    print(f\"X shape = {X.shape}\")\n",
    "    print(f\"y shape = {y.shape}\")\n",
    "    \n",
    "    tsne_transformer = TSNE(n_components=2, learning_rate='auto', perplexity=p)\n",
    "    X_embedded = tsne_transformer.fit_transform(X)\n",
    "    print(X_embedded.shape)\n",
    "    print(f\"perplexity = {p}, KL = {tsne_transformer.kl_divergence_}\")\n",
    "    tsne_fig.add_trace(go.Scatter(x=X_embedded[:,0],y=X_embedded[:,1], mode='markers', marker_color=y), row=i+1, col=1)\n",
    "    distances[level] = compute_inter_class_distances(X, num_samples_per_class=required_samples_num)\n",
    "tsne_fig.update_layout(height=1200, width=600, title_text=\"patents projection\")\n",
    "tsne_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.histogram(distances[k], bins=20) for k in distances.keys()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
